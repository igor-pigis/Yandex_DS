# Анализ текстов

## Описание проекта

Требуется анализировать комментарии пользователей на английском языке и выделять токсичные, чтобы отправить на модерацию. Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

## Навыки и инструменты

- **python**
- **pandas**
- **numpy**
- nltk.stem.**WordNetLemmatizer**
- sklearn.feature_extraction.text.**TfidfVectorizer**
- sklearn.linear_model.**LogisticRegression**
- sklearn.ensemble.**RandomForestClassifier**
- catboost.**CatBoostClassifier**
- BertModel
- LightGBM

## Вывод

В этой работе нам предстояло научить модели классифицировать размеченые тексты и мы испробовали 2 подхода создания фич для классфикации. 
Первый подход заключался в создании фич в виде индексов TF-IDF, в этом подходе мы обучили модели RFC, LR,DTC , LightGBM и наилучшее f1 score показала модешь LogisticRegression. Она была выбрана для теста и на тесте показала значение f1 score равное 0.78. 
Второй подход в создании фич заключался в использовании предобученной модели BERT, которую мы дообучали уже на наших данных. Для модели BERT были использованы только 10% данных. Логистическая регрессия на модели BERT показала довольно низкое значение f1 score. 
Таким образом наилучший результат мы смогли достигнуть путем использования моделей основанных на фичах TF-IDF.
Но стоит заметить, что модель BERT имеет большой потенциал, т.к. мы использовали малую часть имеющихся данных для обучения модели.
